\documentclass{article}

\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage[french]{babel}
\usepackage{hyperref}

\title{Tolkienizer}
\author{LI, Xining \and MARTINEZ, Hermes \and MICKUS, Timothee}

\begin{document}

\maketitle

\clearpage

\section{Présentation générale}
\par
Le présent document correspond au rapport sur le développement et l'analyse du projet 2018 d'Industrialisation du TAL pour l'Université Paris Diderot.
Le projet consistait en l'implémentation d'un script de pseudonymisation d'un sous-ensemble du corpus ENRON.
Il reprend tous les éléments nécessaires à la compréhension de la tâche, du script implémenté, et à l'analyse des résultats produits.

\subsection{Éléments introductifs}
\par
L'un des défis majeurs des applications de Traitement Automatique du Langage (TAL) est d'ordre éthique: comment garantir le droit à l'anonymat des particuliers lorsqu'on utilise comme matières premières leurs informations personnelles?
Cette question éthique est d'autant prégnante à ce jour que l'usage de données en quantités massives - on pensera évidemment aux applications "Big Data" - se répand et que le transfert d'informations s'accèlèrent - ce qu'a impliqué la révolution d'Internet.
Ces nouvelles applications impliquent en outre le stockage et le traitement automatique des informations personnelles: si c'est une aubaine pour les domaines comme le TAL qui se consacrent à l'étude des informations que communique une personne, cela implique un débat sur les plans juridiques et éthiques quant à leur emploi à des fins qui peuvent être non seulement scientifiques, mais aussi commerciales, comme dans le cas du marketing ciblé.
\par
Le problème de la confidentialité des données personnelles est ancien: pour le domaine médical, il remonte à la Grèce Antique et à Hippocrate.
On comprend que des informations personnelles, confiées à un particulier dans un cadre précis, devraient d'un point de vue moral ne pas être divulguées.
Cependant comment établir les limites de ce cadre?
Comment définir ce qu'est une information qui relève du domaine privé, et ce qu'est une information qui relève du domaine publique?
\par
L'anonymisation des données personnelles permet de résoudre une partie de ces problèmes: si l'on conserve les informations personnelles de chacun tout en empêchant l'identification desdites informations à la personne dont elles proviennent, on permet en un sens de protéger l'anonymat du particulier.
En effet le particulier demeure certain que ses informations personnelles et privées ne sont pas connues comme étant les siennes.
Si l'on divulgue les données personnelles, on empêche cependant qu'on puisse les associer à un individu particulier, ce qui rend moins saillant le problème éthique de cette divulgation.
\par
En revanche, plusieurs difficultés peuvent poindre dès qu'on anonymise un texte, et notamment dans le cas des applications en TAL.
On doit notamment pouvoir s'appuyer sur une définition claire de ce qui constitue une mention d'un particulier à anonymiser.
Typiquement, toute information permettant l'identification doit être retirée : on pensera évidemment à supprimer toute information permettant l'identification de manière directe, comme les noms, prénoms, adresses physiques et électroniques, numéros de téléphones...
Mais selon cette logique, on devrait aussi retirer toute information permettant une identification indirecte: aussi les données qui, recoupées, permettent de distinguer un individu en particulier devraient de même être expurgées des données exploitées.
Cependant ces données permettant une identification indirecte se retrouvent d'une part être difficles à détecter, d'autre part pontentiellement constituer l'intégralité des données exploitables.
Une autre difficulté tout aussi évidente est que retirer toute mention d'un particulier rend la lecture difficile, et conduit aussi à l'introduction d'un artefact dans les données que traitera l'application.
\par
S'il est difficile de rémédier à la première de ces deux problématiques, la seconde, en revanche, peut trouver une réponse dans la pseudonymisation.
Plutôt que du supprimer brutalement les références directes, on préférera leur substituer des informations neutralisées, ne correspondant à aucun individu réel.
On souligne aussi souvent, en outre, que la première problématique est difficile à exploiter, car utiliser de telles données pour une identification indirecte demande des moyens conséquents.
La pseudonymisation s'avère donc, en pratique, une solution envisageable à la question éthique de la protection des informations privées.

\subsection{Définitions}
Nous utiliserons les termes suivants au cours de ce rapport:
\paragraph{Traitement automatique du Langage} (TAL) Domaine scientifique et technologique se rapportant à l'étude des traces langagières de manière automatique (en particulier informatique).
\paragraph{Entités Nommées} ("\textit{Named Entities}", NE) Référence dans un texte à un individu du monde réel, ou permettent d'identifier un individu du monde réel particulier.
En particulier: noms, prénoms, noms d'entreprises ou de lieux, adresses physiques ou éléctroniques (emails, URL et IP), numéros de téléphones ou identifiants administratifs.
\paragraph{Reconnaissance d'Entités Nommées} ("\textit{Named Entities Recognition}", NER) Tâche de TAL correspondant à indiquer, dans un texte donné, quelles NE sont présentes, et à quel endroit du texte.
\paragraph{Anonymisation} Tâche de TAL correspondant à la suppression des Entités Nommées dans un texte.
\paragraph{Pseudonymisation} Tâche de TAL correspondant au remplacement des Entités Nommées dans un texte par une séquence ne référant à aucun individu du monde réel.
\paragraph{Coréférence} Les NE qui renvoient au même individu réel partagent la même coréférence. 

\subsection{Présentation du projet}
\subsubsection{Présentation de la tâche spécifique}
\par
Ce projet consiste en l'implémentation d'un outil pour pseudonynmiser un sous-ensemble du corpus ENRON, sans rien perdre des informations pragmatiques quant aux différents locuteurs (locuteur, allocutaire, coréférences, registres de langue, anaphores...).
Ce corpus correspond à une collection d'emails envoyés et stockés par la société Enron et sortis du domaine privé.
La tâche inclut également une évaluation des performances de l'outil, les mo<yens qu'il met en oeuvre et une analyse de ses limites.
\subsubsection{Données à traiter}
\par
Le corpus ENRON est une collection de mails écrits et reçus par la société Enron.
Il a été constitué au cours de la banqueroute de la société due à des manipulations fiscales frauduleuses, afin d'alimenter l'enquête subséquente au dépôt de bilan.
Tombé dans le domaine public suite à son usage juridique, la taille importante du corpus (160 Go, soit plus de 600,000 emails) l'a rendu assez difficile à manipuler.
L'extrait du corpus à traiter ici ne contient que 7,875 emails.
Nous avons recensé dans ceux-ci 31,148 mentions d'organisations (3,845 mentions distinctes), 41,185 mentions de lieux (2,734 mentions distinctes) et 121,105 mentions de personnes (8,549 mentions distinctes).
\par
L'intérêt d'un tel corpus est qu'il est constitué de données réelles, présentant ainsi des contextes variés d'occurences de NE, ainsi que des défis importants en terme de résolutions de coréférences de ces NE.
Le corpus ENRON est par ailleurs l'un des rares corpus massifs de mails à l'origine privés accessibles publiquement.

\section{Implémentation}

\subsection{Choix des outils}
\par
Une série de choix techniques a guidé l'implémentation de ce programme.
\par
L'un des premiers sujets de questionnement que nous avons eu a été celui du langage de programmation.
Nous nous étions déjà préalablement familiarisé avec Java et Python (et notamment sa librairie NLTK).
Nous avons finalement choisi d'utiliser le langage de programmation Groovy, pour plusieurs raisons.
Premièrement, la syntaxe était assez permissive et similaire à Java pour ne pas poser de défi technique.
Secondement, Grapes, qui est intégré dans la distributuion standard de Groovy, permet une gestion de projet et des dépendances très simple.
Troisièmement, l'interfaçage avec les librairies Java se fait sans aucune difficulté en Groovy.
Enfin, l'existence d'un interpréteur pour Groovy permet une prise en main rapide.
\par
Une seconde question que nous avons abordée concernait le choix des librairies externes.
Nous en avons comparé deux en particulier: Apache OpenNLP et Stanford CoreNLP.
Elles nous semblaient toutes deux pertinentes dans le cadre de ce projet, car proposaient toutes deux des fonctionnalités pour la tâche NER.
Nous avons conclu qu'en termes de performances et de maniabilités, la librairie Stanford CoreNLP était supérieure à Apache OpenNLP.
Plus précisément, Apache OpenNLP ne proposait de détection que pour les seules personnes, tandis que Stanford CoreNLP permettait la détection de lieux, personnes et organisations à l'aide d'un premier module, et emails et URL à l'aide d'un second.
Les librairies Python que nous avons étudiées étaient moins performantes en termes de temps de calcul, ce qui nous a conforté dans notre choix d'utiliser Groovy.
\par
La dernière question technique que nous mentionnons ici a été de savoir par quoi remplacer les NE  que nous aurions extraites.
La suppression pure et simple de celles-ci correspondrait à une tâche d'anonymisation.
La subtstition par un label par défaut pour chaque élément aurait été envisageable, mais nuisait beaucoup à l'idiomaticité du corpus.
Notre choix s'est donc porté sur un remplacement des références à des individus réels par des références à des individus fictifs.
Il nous fallait donc un univers fictif qui remplissent plusieurs critères: il devait à la fois être très fourni en noms et en lieux, ainsi qu'être suffisamment répandu et accessible pour que nous puissions trouver des ressources libres pour ce projet.
L'univers fictif qui répondait le mieux à ces critères était celui de J.R.R. Tolkien; en effet le volume de ses oeuvres se chiffre en milliers de pages (sans même prendre en compte ses notes), et il existe une importante communauté de fans et de nombreux sites internets qui y sont dédiés.
\par
Enfin, nous avons mis en place un dépôt git afin de disposer d'un système de versionnage pour ce travail en commun. Il est accessible \href{https://github.com/Sachka/Tolkienizer}{à cette URL}.

\subsection{Constitution des ressources nécessaires}
\par
Les différents choix techniques que nous avons faits nous ont conduit à créer manuellement plusieurs ressources.
\par
Le plus urgent a été la collection de noms de lieux et de personnes issues de l'univers de J.R.R. Tolkien.
Pour ce faire, nous avons capturé la structure de pages issues de ressources libres.
Les noms de personnes ont étés récupérés du DOM la page \href{https://www.behindthename.com/namesakes/list/tolkien/alpha}{Behind The Name}; les noms de lieux de la structure wiki de la page \href{http://tolkiengateway.net/w/index.php?title=List_of_Place_Names}{Tolkien Gateway} et du dom de plusieurs pages issues du site \href{http://www.glyphweb.com/arda/default.asp}{The encyclopedia of Arda}.
Les DOM ont ensuite été transformés à l'aide d'utilitaires UNIX, notamment grep et sed.
Nous avons converti la structure tabulaire du tableau de Behind The Name en format csv, utilisant la tabulation comme séparateur.
Certains noms de familles (notamment les indices dynastiques comme "Thorin III") ont été supprimés pour des raisons d'utilité à la tâche.
Ces informations ont été sauvegardées dans le fichier names.txt.
Les noms de lieux de Tolkien Gateway ont été manuellement normalisés, puis triés et rendus uniques à l'aide des commandes UNIX sort et uniq.
La liste en sortie a été sauvegardée dans le fichier places.txt.
Les deux fichiers ont été concaténés pour produire le fichier voc.txt, que nous utilisons pour la production de noms d'organisations.
\par
Le second type de ressources que nous avons traité consiste en l'extraction de modèles pour la librairie Stanford CoreNLP.

\subsection{Architecture}
\par
Le programme en lui-même se constitue de deux fichiers, extractor.gy et sudonizing.gy.
Le second gère la pseudonymisation des NE extraites.
Le premier permet de gérer le processus itératif : lire les mails source, extraire les NE à pseudonymiser, gérer l'appel au second fichier pour pseudonymiser les NE, puis enregistrer les mails pseudonymisés.
Les deux fichiers groovy sont déclarés dans le même package afin d'en simplifier l'usage.
Les ressources utilisées par les scripts sont consignés dans le répertoire ressource.
\par
TODO : define extractor.gy
\par
Le fichier sudonyzing.gy contient plusieurs classes pour gérer la pseudonymisation des NE.
La classe PersonWrapper est une classe cannonique qui permet simplement de simplifier la lecture pour les NE référent à des êtres humains.
\par
Les autres classes implémentent toutes l'interface Sudonizer, qui typologiquement définit un objet qui peut substituer de manière systématique un pseudonyme à une NE.
Cette interface déclare deux méthodes: sudonize(rawString), qui correspond à pseudonymiser un exemple, et getRegister(), qui correspond à obtenir le registre de correspondances entre NE et pseudonymes.
\par
La classe SimpleSudonizer est l'implémentation la plus basique de cette interface.
Elle correpsond à la substition systématique et directe d'une chaîne de caractère par une autre, et ne met en jeu aucun autre mécanisme.
\par
La classe AwareSudonizer est une implémentation qui permet de pseudonymiser en étant conscient des pseudonymes précédemment donnés.
Elle est conçue comme un wrapper: elle se base sur la prédiction d'un autre objet Sudonizer si elle ne trouve aucun pseudonyme dans le registre.
L'intérêt de cette classe est par ailleurs que le registre peut être global, ce qui permet alors de proposer un pseudonyme qui soit consistent avec l'ensemble des pseudonymes des Sudonizer partageant le même registre global.
\par
La classe PersonSudonizer est une implémentation de l'interface Sudonizer spécifiquement dédiée à la pseudonymisation des êtres humains.
Elle permet de conserver les informations quant au genre de la personne, ainsi que de conserver la forme de la mention, et ce de manière systématique.
Différents individus partageant le même prénom partageront (au moins en partie) le même pseudonyme, et différents individus possédant le même nom de famille partageront le même nom de famille en pseudonyme.
Qui plus est la forme de la mention est respectée: si l'on mentionne seulement un prénom ou un nom, alors le pseudonyme associé n'est composé que d'un prénom ou d'un nom.
Parreillement si l'on mentionne une identité complète, alors le pseudonyme retourné contiendra un prénom et un nom.
\par
La classe OrgSudonizer est une implémentation qui permet de pseudonymiser un nom d'organisation.
Elle repose sur un mécanisme génératif : les pseudonymes qu'elle propose sont construits semi-aléatoirement, en associant deux noms tirés d'un fichier vocabulaire et un suffixe tiré d'une brève liste pour rendre lisible le fait qu'il s'agisse d'un nom d'entreprise.
En effet nous n'avons pas trouvé dans l'univers de J.R.R. Tolkien un ensemble d'organisations (qu'il s'agisse d'ethnies, de pays, de magasins ou autres) qui fut assez grand pour s'appliquer à l'ensemble des noms d'organisations présent dans notre corpus.
La stratégie générative s'est donc avérée ici nécessaire.

\subsection{Emploi du script}

\section{Discussion}
\subsection{Limitations}
\par
Le script possède plusieurs limitations dues à sa conception d'une part, dues à la qualité des outils d'autre part, et enfin, dues à la tâche de pseudonymisation elle-même.
\par
Les limitations internes à l'outil peuvent se distinguer en deux groupes.
Premièrement, le script est conçu selon la lecture de ressources.
Notamment, les classes pour la pseudonymisation (et en particulier SimpleSudonizer) sont extrêmement dépendante d'un vocabulaire préalablement constitué, et ce pour toutes les substitutions effectuées.
Un exemple parlant est celui des 

\section{Conclusion}

\end{document}

