\documentclass{article}

\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage[french]{babel}
\usepackage{hyperref}

\title{Projet Industrie du TAL}
\author{LI, Xining \and MARTINEZ, Hermes \and MICKUS, Timothee}

\begin{document}

\maketitle

\clearpage

\section{Introduction}

étude des besoins (quels types de NE, das quelles proportions, formatés comment),
études des solutions (quels outils, avec quels prérequis, pour faire quoi),
présentation du programme (technologies et ressources employées, architecture, inputs/outputs/options),
présentation du projet (constitution des ressources, tests des outils, indications quantitatives des résultats),
discussion (interprétations, points à améliorer, conclusion).

\subsection{Présentation générale}
\par
L'un des défis majeurs des applications de Traitement Automatique du Langage (TAL) est d'ordre éthique: comment garantir le droit à l'anonymat des particuliers lorsqu'on utilise comme matières premières leurs informations personnelles?
Cette question éthique est d'autant prégnante à ce jour que l'usage de données en quantités massives - on pensera évidemment aux applications "Big Data" - se répand et que le transfert d'informations s'accèlèrent - ce qu'a impliqué la révolution d'Internet.
Ces nouvelles applications impliquent en outre le stockage et le traitement automatique des informations personnelles: si c'est une aubaine pour les domaines comme le TAL qui se consacrent à l'étude des informations que communique une personne, cela implique un débat sur les plans juridiques et éthiques quant à leur emploi à des fins qui peuvent être non seulement scientifiques, mais aussi commerciales, comme dans le cas du marketing ciblé.
\par
Le problème de la confidentialité des données personnelles est ancien: pour le domaine médical, il remonte à la Grèce Antique et à Hippocrate.
On comprend que des informations personnelles, confiées à un particulier dans un cadre précis, devraient d'un point de vue moral ne pas être divulguées.
Cependant comment établir les limites de ce cadre?
Comment définir ce qu'est une information qui relève du domaine privé, et ce qu'est une information qui relève du domaine publique?
\par
L'anonymisation des données personnelles permet de résoudre une partie de ces problèmes: si l'on conserve les informations personnelles de chacun tout en empêchant l'identification desdites informations à la personne dont elles proviennent, on permet en un sens de protéger l'anonymat du particulier.
En effet le particulier demeure certain que ses informations personnelles et privées ne sont pas connues comme étant les siennes.
Si l'on divulgue les données personnelles, on empêche cependant qu'on puisse les associer à un individu particulier, ce qui rend moins saillant le problème éthique de cette divulgation.
\par
En revanche, plusieurs difficultés peuvent poindre dès qu'on anonymise un texte, et notamment dans le cas des applications en TAL.
On doit notamment pouvoir s'appuyer sur une définition claire de ce qui constitue une mention d'un particulier à anonymiser.
Typiquement, toute information permettant l'identification doit être retirée : on pensera évidemment à supprimer toute information permettant l'identification de manière directe, comme les noms, prénoms, adresses physiques et électroniques, numéros de téléphones...
Mais selon cette logique, on devrait aussi retirer toute information permettant une identification indirecte: aussi les données qui, recoupées, permettent de distinguer un individu en particulier devraient de même être expurgées des données exploitées.
Cependant ces données permettant une identification indirecte se retrouvent d'une part être difficles à détecter, d'autre part pontentiellement constituer l'intégralité des données exploitables.
Une autre difficulté tout aussi évidente est que retirer toute mention d'un particulier rend la lecture difficile, et conduit aussi à l'introduction d'un artefact dans les données que traitera l'application.
\par
S'il est difficile de rémédier à la première de ces deux problématiques, la seconde, en revanche, peut trouver une réponse dans la pseudonymisation.
Plutôt que du supprimer brutalement les références directes, on préférera leur substituer des informations neutralisées, ne correspondant à aucun individu réel.
On souligne aussi souvent, en outre, que la première problématique est difficile à exploiter, car utiliser de telles données pour une identification indirecte demande des moyens conséquents.
La pseudonymisation s'avère donc, en pratique, une solution envisageable à la question éthique de la protection des informations privées.

\subsection{Définitions}
Nous utiliserons les termes suivants au cours de ce rapport:
\paragraph{Traitement automatique du Langage} (TAL) Domaine scientifique et technologique se rapportant à l'étude des traces langagières de manière automatique (en particulier informatique).
\paragraph{Entités Nommées} ("\textit{Named Entities}", NE) Référence dans un texte à un individu du monde réel, ou permettent d'identifier un individu du monde réel particulier.
En particulier: noms, prénoms, noms d'entreprises ou de lieux, adresses physiques ou éléctroniques (emails, URL et IP), numéros de téléphones ou identifiants administratifs.
\paragraph{Reconnaissance d'Entités Nommées} ("\textit{Named Entities Recognition}", NER) Tâche de TAL correspondant à indiquer, dans un texte donné, quelles NE sont présentes, et à quel endroit du texte.
\paragraph{Anonymisation} Tâche de TAL correspondant à la suppression des Entités Nommées dans un texte.
\paragraph{Pseudonymisation} Tâche de TAL correspondant au remplacement des Entités Nommées dans un texte par une séquence ne référant à aucun individu du monde réel.
\paragraph{Coréférence} Les NE qui renvoient au même individu réel partagent la même coréférence. 


\section{Présentation du projet}
\subsection{Présentation de la tâche spécifique}
Ce projet consiste en l'implémentation d'un outil pour pseudonynmiser un sous-ensemble du corpus ENRON, sans rien perdre des informations pragmatiques quant aux différents locuteurs (locuteur, allocutaire, coréférences, registres de langue, anaphores...).
Ce corpus correspond à une collection d'emails envoyés et stockés par la société Enron et sortis du domaine privé.
La tâche inclut également une évaluation des performances de l'outil, les mo<yens qu'il met en oeuvre et une analyse de ses limites.

\subsection{Données à traiter}
\par
Le corpus ENRON est une collection de mails écrits et reçus par la société Enron.
Il a été constitué au cours de la banqueroute de la société due à des manipulations fiscales frauduleuses, afin d'alimenter l'enquête subséquente au dépôt de bilan.
Tombé dans le domaine public suite à son usage juridique, la taille importante du corpus (160 Go, soit plus de 600,000 emails) l'a rendu assez difficile à manipuler.
L'extrait du corpus à traiter ici ne contient que 7,875 emails.
Nous avons recensé dans ceux-ci 31,148 mentions d'organisations (3,845 mentions distinctes), 41,185 mentions de lieux (2,734 mentions distinctes) et 121,105 mentions de personnes (8,549 mentions distinctes).
\par
L'intérêt d'un tel corpus est qu'il est constitué de données réelles, présentant ainsi des contextes variés d'occurences de NE, ainsi que des défis importants en terme de résolutions de coréférences de ces NE.
Le corpus ENRON est par ailleurs l'un des rares corpus massifs de mails à l'origine privés accessibles publiquement.

\section{Implémentation}

\subsection{Choix des outils}
\par
Une série de choix techniques a guidé l'implémentation de ce programme.
\par
L'un des premiers sujets de questionnement que nous avons eu a été celui du langage de programmation.
Nous nous étions déjà préalablement familiarisé avec Java et Python (et notamment sa librairie NLTK).
Nous avons finalement choisi d'utiliser le langage de programmation Groovy, pour plusieurs raisons.
Premièrement, la syntaxe était assez permissive et similaire à Java pour ne pas poser de défi technique.
Secondement, Grapes, qui est intégré dans la distributuion standard de Groovy, permet une gestion de projet et des dépendances très simple.
Troisièmement, l'interfaçage avec les librairies Java se fait sans aucune difficulté en Groovy.
Enfin, l'existence d'un interpréteur pour Groovy permet une prise en main rapide.
\par
Une seconde question que nous avons abordée concernait le choix des librairies externes.
Nous en avons comparé deux en particulier: Apache OpenNLP et Stanford CoreNLP.
Elles nous semblaient toutes deux pertinentes dans le cadre de ce projet, car proposaient toutes deux des fonctionnalités pour la tâche NER.
Nous avons conclu qu'en termes de performances et de maniabilités, la librairie Stanford CoreNLP était supérieure à Apache OpenNLP.
Plus précisément, Apache OpenNLP ne proposait de détection que pour les seules personnes, tandis que Stanford CoreNLP permettait la détection de lieux, personnes et organisations à l'aide d'un premier module, et emails et URL à l'aide d'un second.
Les librairies Python que nous avons étudiées étaient moins performantes en termes de temps de calcul, ce qui nous a conforté dans notre choix d'utiliser Groovy.
\par
La dernière question technique que nous mentionnons ici a été de savoir par quoi remplacer les NE  que nous aurions extraites.
La suppression pure et simple de celles-ci correspondrait à une tâche d'anonymisation.
La subtstition par un label par défaut pour chaque élément aurait été envisageable, mais nuisait beaucoup à l'idiomaticité du corpus.
Notre choix s'est donc porté sur un remplacement des références à des individus réels par des références à des individus fictifs.
Il nous fallait donc un univers fictif qui remplissent plusieurs critères: il devait à la fois être très fourni en noms et en lieux, ainsi qu'être suffisamment répandu et accessible pour que nous puissions trouver des ressources libres pour ce projet.
L'univers fictif qui répondait le mieux à ces critères était celui de J.R.R. Tolkien; en effet le volume de ses oeuvres se chiffre en milliers de pages (sans même prendre en compte ses notes), et il existe une importante communauté de fans et de nombreux sites internets qui y sont dédiés.
\par
Enfin, nous avons mis en place un dépôt git afin de disposer d'un système de versionnage pour ce travail en commun. Il est accessible \href{https://github.com/Sachka/Tolkienizer}{à cette URL}.

\subsection{Constitution des ressources nécessaires}
\par
Les différents choix techniques que nous avons faits nous ont conduit à créer manuellement plusieurs ressources.
\par
Le plus urgent a été la collection de noms de lieux et de personnes issues de l'univers de J.R.R. Tolkien.
Pour ce faire, nous avons capturé la structure de pages issues de ressources libres: les noms de personnes ont étés récupérés du DOM la page \href{https://www.behindthename.com/namesakes/list/tolkien/alpha}{Behind The Name}, et les noms de lieux de la structure wiki de la page \href{http://tolkiengateway.net/w/index.php?title=List_of_Place_Names}{Tolkien Gateway}.
Les DOM ont ensuite été transformés à l'aide d'utilitaires UNIX, notamment grep et sed.
Nous avons converti la structure tabulaire du tableau de Behind The Name en format csv, utilisant la tabulation comme séparateur.
Certains noms de familles (notamment les indices dynastiques comme "Thorin III") ont été supprimés pour des raisons d'utilité à la tâche.
Ces informations ont été sauvegardées dans le fichier names.txt.
Les noms de lieux de Tolkien Gateway ont été manuellement normalisés, puis triés et rendus uniques à l'aide des commandes UNIX sort et uniq.
La liste en sortie a été sauvegardée dans le fichier places.txt.
Les deux fichiers ont été concaténés pour produire le fichier voc.txt, que nous utilisons pour la production de noms d'organisations.

\par

\subsection{Architecture}
Le programme se constitue de 2 fichiers, extractor.gy et sudonizing.gy, le premier pour faire la lecture des mails sources Enrons et l'extraction des entités nommés qui contiennent des informations à anonymiser, le deuxième gère la pseudonymisation des entités nommés extraits. 


\section{Résultats}

\section{Conclusion}

\end{document}

