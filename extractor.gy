#!usr/bin/env groovy

package tolkienizer

@Grab ('edu.stanford.nlp:stanford-corenlp:3.8.0')
@Grab ('org.slf4j:slf4j-log4j12:1.7.10')
import java.nio.charset.StandardCharsets
import java.nio.file.Files
import java.nio.file.Paths
import java.io.StringReader
import edu.stanford.nlp.ie.AbstractSequenceClassifier
import edu.stanford.nlp.ie.crf.*
import edu.stanford.nlp.io.IOUtils
import edu.stanford.nlp.ling.CoreLabel
import edu.stanford.nlp.ling.CoreAnnotations
import edu.stanford.nlp.util.*
import edu.stanford.nlp.pipeline.*
import edu.stanford.nlp.process.PTBTokenizer
import edu.stanford.nlp.ling.HasWord
import edu.stanford.nlp.process.CoreLabelTokenFactory
import java.io.FileInputStream
import java.util.regex.Matcher
import java.util.regex.Pattern



// This function reads all mails and loads them into an ArrayList for testing purposes
void loadMailsToArray(dataDir, mailList) throws IOException {
    dataDir.eachFile() { child ->
        if (child.isFile()) {
            pathAndMail = []
            filePath = child.getParent() + "/" + child.getName()
            mail = new String(Files.readAllBytes(Paths.get(child.getAbsolutePath())), StandardCharsets.UTF_8)
            pathAndMail.add(filePath)
            pathAndMail.add(mail)
            mailList.add(pathAndMail)
        } else { loadMailsToArray(child, mailList) }
    }
}

// This function returns a tokenized string
def tokenizeMail(mail) {
    splittedMail = mail.split("\n")
    cat = ""
    for (sentence in splittedMail) {
        ptbt = new PTBTokenizer<CoreLabel>(new StringReader(sentence), new CoreLabelTokenFactory(), "")
        while (ptbt.hasNext()) {
            slabel = ptbt.next()
            cat = cat + label + " "
        }
        cat = cat.trim() + "\n"
    }
    return cat
}

// This function returns a list of recognized NE using Regular Expressions as dectection method
def createSupplementaryNEList(mailList, regexMAP) {
    entityList = []
    patternDict = [:]
    for (entry in regexMap.entrySet()) {
        Pattern p = Pattern.compile((entry.getValue()))
        patternDict[entry.getKey()] = p
    }
    for (mail in mailList) {
        neList = []
        tokenized_mail = mail[1] // [0] corresponds to path, [1] is the mail itself
        patternDict.each { cat, p ->
            m = p.matcher(tokenized_mail)
            if (m.find()) {
                triple = new Triple(String, String, String)
                triple.setFirst(cat)
                triple.setSecond(m.group(0))
                triple.setThird("---")
                neList.add(triple)
            }
        }
        entityList.add(neList)
    }
    return entityList
}

// This function returns a list of recognized NE
def createNEList(abstractSequenceClassifier, mailList, genderMapping) {
    entityList = []
    for (mail in mailList) {
        offsetList = abstractSequenceClassifier.classifyToCharacterOffsets(mail[1])
        nameList = []
        for (item in offsetList) {
            triple = new Triple(String, String, String)
            name = mail[1].substring(item.second(), item.third()).trim()
            triple.setFirst(item.first)
            triple.setSecond(name)
            triple.setThird("---")
            // >>>>> GENDER MAPPING TEST
            fname = name.split(" ")[0]
            if (item.first.equals("PERSON")) {
                gender = genderMapping.get(fname.toLowerCase())
                if (gender == null) gender = "UNDEFINED"
                triple.setSecond(gender[0].toLowerCase() + " " + name)
                triple.setThird(gender)
            }
            // >>>>>
            nameList.add(triple)
        }
        entityList.add(nameList)
    }
    return entityList
}

// This prints a mail (int) with tagged NE, from a list of mails, using a classifier to show NE tags
void printNEInMail(ImailNumber, listOfMails, abstractSequenceClassifier) {
    if (mailNumber < listOfMails.size()) println abstractSequenceClassifier.classifyWithInlineXML(listOfMails.get(mailNumber))
    else println "Invalid mail number"
}
    


// ** ITERATIVE PROGRAM **

// LOADING MAILS TO MEMORY
corpusPath = new File("./resources/data/")
mails = []
loadMailsToArray(corpusPath, mails)
println "$mails.size mails loaded correctly."
println()
println(mails[0])

// LOADING PROPERTIES
genderMapFile = "./resources/stanford_corenlp/gender_map"
genderMap = new Properties()
genderMap.load(new FileInputStream(genderMapFile))
regexMapFile = "./resources/stanford_corenlp/email_url_regex"
regexMap = new Properties()
regexMap.load(new FileInputStream(regexMapFile))



// CRF CLASSIFIER STANFORD CORENLP NE EXTRACTION
serializedClassifier = "./resources/stanford_corenlp/english.nowiki.3class.caseless.distsim.crf.ser.gz"
classifier = CRFClassifier.getClassifier(serializedClassifier)
// ll = createNEList(classifier, mails, genderMap)
// println(ll[0])
// println "$ll.size mails tagged with a CRFCLassifier."
println()


// REGEX NE EXTRACTION
rl = createSupplementaryNEList(mails, regexMap)
println(rl[0])
println "$rl.size mails tagged with a REGEX Classifier."



System.exit(0)
sudonizersMap =["LOCATION": new SimpleSudonizer(new File("./resources/places.txt")), "ORGANIZATION":  new OrgSudonizer(new File("./resources/voc.txt")), "PERSON": new PersonSudonizer(new File("./resources/names.txt"))]

def sudonize(type, toSudonize) {
	return sudonizersMap[type] == null ? null : sudonizersMap[type].sudonize(toSudonize)
}

org = [] as Set
person = [] as Set
loc = [] as Set
for (mail in ll) {
    for (tlist in mail) {
        for (t in tlist) {
            if (t.first().equals("PERSON")) {
                person << t.second()
                println sudonize(t.first(), "m " + t.second())
            }
            else if (t.first().equals("ORGANIZATION")) {
                org << t.second()
                println sudonize(t.first(), t.second())
            }
            else if (t.first().equals("LOCATION")) {
                loc << t.second()
                println sudonize(t.first(), t.second())
            }
        }
    }
}
println "${org.size()} ORGS"
println "${loc.size()} LOCS"
println "${person.size()} HUMANS"
