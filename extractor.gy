#!usr/bin/env groovy

package tolkienizer

@Grab ('edu.stanford.nlp:stanford-corenlp:3.8.0')
@Grab ('org.apache.commons:commons-lang3:3.7')
@Grab ('org.slf4j:slf4j-log4j12:1.7.10')
import java.nio.charset.StandardCharsets
import java.nio.file.Files
import java.nio.file.Paths
import java.io.StringReader
import edu.stanford.nlp.ie.AbstractSequenceClassifier
import edu.stanford.nlp.ie.crf.*
import edu.stanford.nlp.io.IOUtils
import edu.stanford.nlp.ling.CoreLabel
import edu.stanford.nlp.ling.CoreAnnotations
import edu.stanford.nlp.util.*
import edu.stanford.nlp.pipeline.*
import edu.stanford.nlp.process.PTBTokenizer
import edu.stanford.nlp.ling.HasWord
import edu.stanford.nlp.process.CoreLabelTokenFactory
import java.io.FileInputStream
import java.io.OutputStreamWriter
import java.util.regex.Matcher
import java.util.regex.Pattern
import org.apache.commons.lang3.StringUtils



// This function reads all mails and loads them into an ArrayList for testing purposes
void loadMailsToArray(dataDir, mailList) throws IOException {
    dataDir.eachFile() { child ->
        if (child.isFile()) {
            pathAndFile= []
            filePath = child.getParent() + "/" + child.getName()
            mail = new String(Files.readAllBytes(Paths.get(child.getAbsolutePath())), StandardCharsets.UTF_8)
            pathAndFile.add(filePath)
            pathAndFile.add(mail)
            mailList.add(pathAndFile)
        } else { loadMailsToArray(child, mailList) }
    }
}

def writeTolkienizedMails(directory, listToWrite) throws IOException {
    outputDir = new File(directory)
    if (!outputDir.exists()) {
        println("Writing mails to " + outputDir.getName())
        outputDir.mkdir()
    }
    for (element in listToWrite) {
        outputFilePath = directory + "/" + element[0] + "tolkien"
        // dirList = element[0].split("/")
        // currentDir = directory
        // for (int i = 0; i < dirList.size() - 1; i++) {
        //     currentDir = currentDir + "/" + dirList[i]
        //     creator = new File(currentDir)
        //     if (!creator.exists())
        //     creator.mkdir()
        // }
        mailFile = new File(outputFilePath)
        parentFolder = new File(mailFile.getParent())
        parentFolder.mkdirs()
        mailFile.createNewFile()
        writer = new OutputStreamWriter(new FileOutputStream(mailFile))
        writer.write(element[1])
        writer.close()
        }
}

// This function returns a tokenized string
def tokenizeMail(mail) {
    splittedMail = mail.split("\n")
    cat = ""
    for (sentence in splittedMail) {
        ptbt = new PTBTokenizer<CoreLabel>(new StringReader(sentence), new CoreLabelTokenFactory(), "")
        while (ptbt.hasNext()) {
            slabel = ptbt.next()
            cat = cat + label + " "
        }
        cat = cat.trim() + "\n"
    }
    return cat
}

// This function returns a list of recognized NE using Regular Expressions as dectection method
def createSupplementaryNEList(mailList, regexMAP) {
    entityList = []
    patternDict = [:]
    for (entry in regexMap.entrySet()) {
        Pattern p = Pattern.compile((entry.getValue()))
        patternDict[entry.getKey()] = p
    }
    for (mail in mailList) {
        neList = []
        tokenized_mail = mail[1] // [0] corresponds to path, [1] is the mail itself
        patternDict.each { cat, p ->
            m = p.matcher(tokenized_mail)
            if (m.find()) {
                triple = new Triple(String, String, String)
                triple.setFirst(cat)
                triple.setSecond(m.group(0))
                triple.setThird("---")
                neList.add(triple)
            }
        }
        entityList.add(neList)
    }
    return entityList
}

// This function returns a list of recognized NE
def createNEList(abstractSequenceClassifier, mailList, genderMapping) {
    entityList = []
    for (mail in mailList) {
        offsetList = abstractSequenceClassifier.classifyToCharacterOffsets(mail[1])
        nameList = []
        for (item in offsetList) {
            triple = new Triple(String, String, String)
            name = mail[1].substring(item.second(), item.third()).trim()
            triple.setFirst(item.first)
            triple.setSecond(name)
            triple.setThird("---")
            // >>>>> GENDER MAPPING TEST
            fname = name.split(" ")[0]
            if (item.first.equals("PERSON")) {
                gender = genderMapping.get(fname.toLowerCase())
                if (gender == null) gender = "UNDEFINED"
                // triple.setSecond(gender[0].toLowerCase() + " " + name)
                triple.setThird(gender)
            }
            // >>>>>
            nameList.add(triple)
        }
        entityList.add(nameList)
    }
    return entityList
}

// This prints a mail (int) with tagged NE, from a list of mails, using a classifier to show NE tags
void printNEInMail(ImailNumber, listOfMails, abstractSequenceClassifier) {
    if (mailNumber < listOfMails.size()) println abstractSequenceClassifier.classifyWithInlineXML(listOfMails.get(mailNumber))
    else println "Invalid mail number"
}


def tolkienize(mailList, neMap) {
    if (mailList.size() != neMap.size()) {
        println("Impossible to tolkienize")
        return null
    }
    tolkienizedMailList = []
    for (int i = 0; i < mailList.size(); i++) {
        tolkienizedMailList.add([mailList[i][0], annonymize(mailList[i][1], neMap[i])])
    }
    return tolkienizedMailList
}

def annonymize(text, definitions) {
    keys = new ArrayList<String>()
    values = new ArrayList<String>()
    for (entry in definitions.entrySet()) {
        keys.add(entry.getKey())
            values.add(String.valueOf(entry.getValue()))
    }
    kArray = keys.toArray(new String[keys.size()])
    vArray = values.toArray(new String[values.size()]) 
    return StringUtils.replaceEach(text, kArray, vArray)
}

def entityMapping(orig, annon) {
    if (orig.size() != annon.size()) {
        println("Impossible to map")
        return null
    }
    mappingList = []
    for (int i = 0; i < orig.size(); i++) {
        HashMap<String,String> mapping = new HashMap<String,String>()
        for (int j = 0; j < orig[i].size(); j++) {
            mapping.put(orig[i][j].second, annon[i][j].second)
        }
        mappingList.add(mapping)
    }
    return mappingList
}

def sudonize(triple) {
    return sudonizersMap[triple.first()] == null ? null : sudonizersMap[triple.first()].sudonize(String.valueOf(triple.second), String.valueOf(triple.third))
}

def sudonizeAll(listOfMails) {
    return  listOfMails.collect({ NETriplets -> NETriplets.collect( { ne -> sudonize(ne.first(), ne.second() ) }) })
}

def createTolkienList(llEntities) {
    llEntities.collect({ listOfTriples ->
        listOfTriples.collect({ triple ->
            return new Triple(triple.first(), sudonize(triple), triple.third())
        })
    }) 
}


// ** ITERATIVE PROGRAM **

// LOADING MAILS TO MEMORY
corpusPath = new File("resources/demo")
eronEmailList= []
loadMailsToArray(corpusPath, eronEmailList)
println "$eronEmailList.size mails loaded correctly."
println()

// LOADING PROPERTIES
genderMapFile = "./resources/stanford_corenlp/gender_map"
genderMap = new Properties()
genderMap.load(new FileInputStream(genderMapFile))
regexMapFile = "./resources/stanford_corenlp/email_url_regex"
regexMap = new Properties()
regexMap.load(new FileInputStream(regexMapFile))



// CRF CLASSIFIER STANFORD CORENLP NE EXTRACTION
serializedClassifier = "./resources/stanford_corenlp/english.nowiki.3class.caseless.distsim.crf.ser.gz"
classifier = CRFClassifier.getClassifier(serializedClassifier)
ll = createNEList(classifier, eronEmailList, genderMap)
println "$ll.size mails tagged with a CRFCLassifier."
println()


// REGEX NE EXTRACTION
rl = createSupplementaryNEList(eronEmailList, regexMap)
println "$rl.size mails tagged with a REGEX Classifier."

// SUDONIZER PARAMETERS
globalRegister =[:]
sudonizersMap =[
    "LOCATION": new SimpleSudonizer(new File("./resources/places.txt"), globalRegister),
    "ORGANIZATION":  new OrgSudonizer(new File("./resources/voc.txt"), globalRegister),
    "PERSON": new PersonSudonizer(new File("./resources/names.txt"), globalRegister),
    "DEFAULT" : new AwareSudonizer(new SimpleSudonizer(new File("./resources/voc.txt"), globalRegister), globalRegister)
]

// TRANSFORMATION PROCESS
// Creating first equivalent Tolkien Entities for NE (ll) and REGEXED NE (rl)
tolkienLL = createTolkienList(ll)
tolkienRL = createTolkienList(rl)


// Creation of list of mappings ERON TO TOLKIEN
eronToTolkienLL = entityMapping(ll, tolkienLL)
eronToTolkienRL = entityMapping(rl, tolkienRL)

// Creation of a partial email list with REGEXED replaced entities
partialEmailList = tolkienize(eronEmailList, eronToTolkienRL)

// Creation of a complete email list with CRF Classifier replaced entities
tolkienEmailList = tolkienize(partialEmailList, eronToTolkienLL)

// Writing results to DIR in first argument
writeTolkienizedMails("Tolkien", tolkienEmailList)
println()
println("End of Program.")



// exampleMail = " FROM: carla@gmail.com TO: hermesm@gmail.com \
// this is an email, sent by ERON to detect websites like www.google.com, places like Central Park or New York,\
// name entities like Scott Kennedy and John Lennon and organizations like Umbrella Corp."

// exampleMail2 = " FROM: carla@gmail.com TO: hermesm@gmail.com \
// this is an email, sent by Sandra Stanner to detect websites like www.google.com, places like Central Area or New York,\
// name entities like Scott Green and Jane Lennon and organizations like Umbrella Corp."

// // Procedure
// exampleList = [["Temp/1.", exampleMail]]
// exampleList.add(["Temp/2.", exampleMail2])

// ll = createNEList(classifier, exampleList, genderMap)


// tl = createTolkienList(ll)

// listofMap = entityMapping(ll, tl)

// exampleTolkienized = tolkienize(exampleList, listofMap)




// writeTolkienizedMails("T", exampleTolkienized)



System.exit(0)



org = [] as Set
person = [] as Set
loc = [] as Set
for (mail in ll) {
    for (tlist in mail) {
        for (t in tlist) {
            if (t.first().equals("PERSON")) {
                person << t.second()
                println sudonize(t.first(), "m " + t.second())
            }
            else if (t.first().equals("ORGANIZATION")) {
                org << t.second()
                println sudonize(t.first(), t.second())
            }
            else if (t.first().equals("LOCATION")) {
                loc << t.second()
                println sudonize(t.first(), t.second())
            }
        }
    }
}
println "${org.size()} ORGS"
println "${loc.size()} LOCS"
println "${person.size()} HUMANS"


