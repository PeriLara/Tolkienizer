#!usr/bin/env groovy
@Grab ('edu.stanford.nlp:stanford-corenlp:3.8.0')
import java.nio.charset.StandardCharsets;
import java.nio.file.Files;
import java.nio.file.Paths;
import java.io.File;
import java.io.StringReader;
import java.util.List;
import java.util.ArrayList;
import edu.stanford.nlp.ie.AbstractSequenceClassifier;
import edu.stanford.nlp.ie.crf.*;
import edu.stanford.nlp.io.IOUtils;
import edu.stanford.nlp.ling.CoreLabel;
import edu.stanford.nlp.ling.CoreAnnotations;
import edu.stanford.nlp.util.*;
import edu.stanford.nlp.pipeline.*;
import edu.stanford.nlp.process.PTBTokenizer
import edu.stanford.nlp.ling.HasWord;
import edu.stanford.nlp.process.CoreLabelTokenFactory;


// This function reads all mails and loads them into an ArrayList for testing purposes
static void loadMailsToArray(File dataDir, ArrayList<String> mailList) throws IOException {
    for (File child : dataDir.listFiles()) {
        if (child.isFile()) {
            byte[] encodedMail = Files.readAllBytes(Paths.get(child.getAbsolutePath()));
            mailList.add(new String(encodedMail, StandardCharsets.UTF_8));
        } else {
            loadMailsToArray(child, mailList);
        }
    }
}
// This function returns a tokenized string
static tokenizeMail(String mail) {
    String[] array = mail.split("\n");
    String cat = new String();
    for (String sentence : array) {
        PTBTokenizer<CoreLabel> ptbt = new PTBTokenizer<>(new StringReader(sentence), new CoreLabelTokenFactory(), "");
        while (ptbt.hasNext()) {
            CoreLabel label = ptbt.next();
            cat = cat + label + " ";
        }
        cat = cat.trim() + "\n";
    }
    return cat;
}

// This function returns a list of recognized NE
static ArrayList<ArrayList<Triple<String, String, String>>> createNEList(AbstractSequenceClassifier cl, ArrayList<String> mailList) {
ArrayList<ArrayList<Triple<String, String, String>>> entityList = new ArrayList<ArrayList<Triple<String, String, String>>>();
    for (String mail : mailList) {
        List<Triple<String, Integer, Integer>> list = cl.classifyToCharacterOffsets(mail);
        List<Triple<String, String, String>> nameList = new ArrayList<Triple<String, String, String>>();
        for (Triple<String, Integer, Integer> item : list) {
            Triple t = new Triple(String, String, String);
            t.setFirst(item.first);
            t.setSecond(mail.substring(item.second(), item.third()));
            t.setThird("---");
            // println(t);
            nameList.add(t);
        }
        entityList.add(nameList);
    }
    return entityList
}

// ITERATIVE PROGRAM

// LOADING MAILS TO MEMORY
File corpusPath = new File("./resources/data/");
ArrayList<String> mails = new ArrayList<String>();
loadMailsToArray(corpusPath, mails);
println(mails.size() + " mails loaded correctly.");

// TEST STANFORD CORENLP
println();
String serializedClassifier = "./resources/stanford_corenlp/english.all.3class.distsim.crf.ser.gz";
AbstractSequenceClassifier<CoreLabel> classifier = CRFClassifier.getClassifier(serializedClassifier);
println();
List<List<Triple<String, String, String>>> NEList = createNEList(classifier, mails);
println(NEList.size());
println(mails.size());

